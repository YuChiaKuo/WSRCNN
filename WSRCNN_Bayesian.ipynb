{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21896,
     "status": "ok",
     "timestamp": 1591585259335,
     "user": {
      "displayName": "郭又嘉",
      "photoUrl": "",
      "userId": "15699708202644108089"
     },
     "user_tz": -480
    },
    "id": "mPCdY2wUXhFB",
    "outputId": "3fb7727c-4561-4883-8082-453ca99651ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import pandas as pd\\nfrom pydrive.auth import GoogleAuth\\nfrom pydrive.drive import GoogleDrive \\nfrom google.colab import auth \\nfrom oauth2client.client import GoogleCredentials\\n \\nauth.authenticate_user()\\ngauth = GoogleAuth()\\ngauth.credentials = GoogleCredentials.get_application_default()\\ndrive = GoogleDrive(gauth)\\nfile_id = '1-lri-HK_aq_UhHnprQTi5zg5sqldKVhm'  #雲端硬碟檔案連結碼\\ndownloaded = drive.CreateFile({'id': file_id})\\ndownloaded.GetContentFile('yahoo_total_data.csv')\\ndata = pd.read_csv('yahoo_total_data.csv')\\nprint(data)\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pandas as pd\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive \n",
    "from google.colab import auth \n",
    "from oauth2client.client import GoogleCredentials\n",
    " \n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "file_id = '1-lri-HK_aq_UhHnprQTi5zg5sqldKVhm'  #雲端硬碟檔案連結碼\n",
    "downloaded = drive.CreateFile({'id': file_id})\n",
    "downloaded.GetContentFile('yahoo_total_data.csv')\n",
    "data = pd.read_csv('yahoo_total_data.csv')\n",
    "print(data)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5931,
     "status": "ok",
     "timestamp": 1591585227448,
     "user": {
      "displayName": "郭又嘉",
      "photoUrl": "",
      "userId": "15699708202644108089"
     },
     "user_tz": -480
    },
    "id": "AKY3FpSwVoKI",
    "outputId": "ad020d76-a85d-41f4-ee5d-9265fef5131b"
   },
   "outputs": [],
   "source": [
    "#!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2507,
     "status": "ok",
     "timestamp": 1591589172800,
     "user": {
      "displayName": "郭又嘉",
      "photoUrl": "",
      "userId": "15699708202644108089"
     },
     "user_tz": -480
    },
    "id": "5YXNz6MkoILI",
    "outputId": "e7dfa17e-c382-468a-edd7-e60a6a67c942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from skopt import gp_minimize #貝氏優化\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2043,
     "status": "ok",
     "timestamp": 1591589172801,
     "user": {
      "displayName": "郭又嘉",
      "photoUrl": "",
      "userId": "15699708202644108089"
     },
     "user_tz": -480
    },
    "id": "k182uNX-XRFa",
    "outputId": "5daeb445-5c62-4499-99b8-e19176662267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 572966 entries, 0 to 572965\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Unnamed: 0  572966 non-null  int64  \n",
      " 1   timestamp   572966 non-null  int64  \n",
      " 2   value       572966 non-null  float64\n",
      " 3   is_anomaly  572966 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 17.5 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/PAPER/SRCNN/yahoo/yahoo_total_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5hBQRUw6oILT"
   },
   "source": [
    "## Generate train data (有Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e4V9rEyJoILU"
   },
   "outputs": [],
   "source": [
    "class gen():\n",
    "    def __init__(self, win_siz, step, nums):\n",
    "        self.control = 0\n",
    "        self.win_siz = win_siz\n",
    "        self.step = step\n",
    "        self.number = nums\n",
    "\n",
    "    def generate_train_data(self, value, label, train_op, back_k=0):\n",
    "        def normalize(a):\n",
    "            amin = np.min(a)\n",
    "            amax = np.max(a)\n",
    "            a = (a - amin) / (amax - amin + 1e-5)\n",
    "            return 3 * a\n",
    "\n",
    "        if back_k <= 5:\n",
    "            back = back_k\n",
    "        else:\n",
    "            back = 5\n",
    "        length = len(value)\n",
    "        tmp = []\n",
    "        for pt in range(self.win_siz, length - back, self.step): # window=128 step=64 跳一次\n",
    "            \n",
    "            head = max(0, pt - self.win_siz)\n",
    "            tail = min(length - back, pt)\n",
    "            data = normalize(np.array(value[head:tail]).astype(np.float64)) # 以 window=128 做切割 (128,1)\n",
    "            #lbs = np.array(label[head:tail]).astype(np.float64)    #有 label\n",
    "            lbs = np.zeros(self.win_siz, dtype=np.int64)\n",
    "\n",
    "            num = np.random.randint(1, self.number)   # [1, number] 之間隨機選一個整數 num\n",
    "            ids = np.random.choice(self.win_siz, num, replace=False)  # 再從 window 之中選 num 個數 為異常\n",
    "            \n",
    "            if train_op:\n",
    "                if (self.win_siz - 6) not in ids:    # control 累積到 100 若沒有 (window - 6) 在選擇內 則加進去 \n",
    "                    self.control += np.random.random()  # [0,1] 之間隨機數\n",
    "                else:\n",
    "                    self.control = 0\n",
    "                if self.control > 100:\n",
    "                    ids[0] = self.win_siz - 6\n",
    "                    self.control = 0\n",
    "\n",
    "                mean = np.mean(data)\n",
    "                dataavg = average_filter(data)\n",
    "                var = np.var(data)\n",
    "\n",
    "                for id in ids: # 將原始data加上異常以覆蓋  np.random.standard_cauchy / np.random.randn() / np.random.standard_t(10)\n",
    "                    data[id] += (dataavg[id] + mean) * np.random.randn() * min((1 + var), 10)   # 製造異常 (保有Label 異常為1)\n",
    "                    lbs[id] = 1\n",
    "            \n",
    "            tmp.append([data.tolist(), lbs.tolist()])\n",
    "            \n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWeKSEfTjoMB"
   },
   "outputs": [],
   "source": [
    "def average_filter(values, n=3):\n",
    "    \"\"\"\n",
    "    Calculate the sliding window average for the give time series.\n",
    "    Mathematically, res[i] = sum_{j=i-t+1}^{i} values[j] / t, where t = min(n, i+1)\n",
    "    :param values: list.\n",
    "        a list of float numbers\n",
    "    :param n: int, default 3.\n",
    "        window size.\n",
    "    :return res: list.\n",
    "        a list of value after the average_filter process.\n",
    "    \"\"\"\n",
    "\n",
    "    if n >= len(values):\n",
    "        n = len(values)\n",
    "\n",
    "    res = np.cumsum(values, dtype=float)\n",
    "    res[n:] = res[n:] - res[:-n]\n",
    "    res[n:] = res[n:] / n\n",
    "\n",
    "    for i in range(1, n):\n",
    "        res[i] /= (i + 1)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5o9HuAD4joMG"
   },
   "source": [
    "## Not One class data (自己加上異常並標全新Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3646,
     "status": "ok",
     "timestamp": 1591589176403,
     "user": {
      "displayName": "郭又嘉",
      "photoUrl": "",
      "userId": "15699708202644108089"
     },
     "user_tz": -480
    },
    "id": "S-FqmPY8oILY",
    "outputId": "c8fab165-ec99-4058-b6f7-8c37257bf325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating train data\n",
      "total fake data size: 8951\n",
      "gen_data shape (8951, 2, 64)\n",
      "train shape: (8951, 2, 64)\n"
     ]
    }
   ],
   "source": [
    "window = 64\n",
    "step = 32\n",
    "num = 5  # upper limit value for the number of anomaly points\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    results = []\n",
    "    print(\"generating train data\")\n",
    "    generator = gen(window, step, num)\n",
    "    \n",
    "    in_timestamp, in_value, in_label = df['timestamp'], df['value'], df['is_anomaly']\n",
    "\n",
    "    if len(in_value) < window:\n",
    "        print(\"value's length < window size\", len(in_value), window)\n",
    "    \n",
    "    half_len = int(len(in_value)/2)\n",
    "    gen_data = generator.generate_train_data(in_value[:half_len], in_label[:half_len], True)  # [in_label==0] 丟原始異常\n",
    "    X_train = np.array(gen_data).astype('float32')\n",
    "    \n",
    "    print('total fake data size:', len(gen_data))\n",
    "    print('gen_data shape', np.array(gen_data).shape)\n",
    "    print('train shape:', np.array(X_train).shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3224,
     "status": "ok",
     "timestamp": 1591589176404,
     "user": {
      "displayName": "郭又嘉",
      "photoUrl": "",
      "userId": "15699708202644108089"
     },
     "user_tz": -480
    },
    "id": "VH0o7Mi0joMJ",
    "outputId": "1ad97c47-2041-4ab6-c655-13b35380408a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3915\n",
      "異常點比例： 0.006832866173560037\n"
     ]
    }
   ],
   "source": [
    "print(sum(in_label==1))\n",
    "print('異常點比例：', sum(in_label==1)/in_value.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "er1HWvZrXRFn"
   },
   "source": [
    "## 未轉SR的Time Series與Label標記情況(前100筆window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2331,
     "status": "ok",
     "timestamp": 1591589176405,
     "user": {
      "displayName": "郭又嘉",
      "photoUrl": "",
      "userId": "15699708202644108089"
     },
     "user_tz": -480
    },
    "id": "tP6P18C-XRFn",
    "outputId": "62fea418-1c8e-4ea5-9477-69e840540709"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in range(100):\\n    print(\\'picture  \\', i)\\n    plt.plot(X_train[:,0][i])\\n    index_changes = np.where(X_train[:,1][i] == 1)\\n    plt.scatter(index_changes, X_train[:,0][i][index_changes], c=\\'red\\', label=\"change point\")\\n    plt.show()'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in range(100):\n",
    "    print('picture  ', i)\n",
    "    plt.plot(X_train[:,0][i])\n",
    "    index_changes = np.where(X_train[:,1][i] == 1)\n",
    "    plt.scatter(index_changes, X_train[:,0][i][index_changes], c='red', label=\"change point\")\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oFK9zJhdoILd"
   },
   "source": [
    "## 計算Spectral Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qok5fYrUjoMM"
   },
   "outputs": [],
   "source": [
    "def spectral_residual(values):\n",
    "    \"\"\"\n",
    "    This method transform a time series into spectral residual series\n",
    "    :param values: list.\n",
    "        a list of float values.\n",
    "    :return: mag: list.\n",
    "        a list of float values as the spectral residual values\n",
    "    \"\"\"\n",
    "    EPS = 1e-8\n",
    "    trans = np.fft.fft(values) #傅立葉變換\n",
    "    mag = np.sqrt(trans.real ** 2 + trans.imag ** 2) #A(f)\n",
    "\n",
    "    maglog = [np.log(item) if abs(item) > EPS else 0 for item in mag]  #L(f)\n",
    "\n",
    "    spectral = np.exp(maglog - average_filter(maglog, n=3)) #R(f)\n",
    "\n",
    "    trans.real = [ireal * ispectral / imag if abs(imag) > EPS else 0\n",
    "                  for ireal, ispectral, imag in zip(trans.real, spectral, mag)]\n",
    "    trans.imag = [iimag * ispectral / imag if abs(imag) > EPS else 0\n",
    "                  for iimag, ispectral, imag in zip(trans.imag, spectral, mag)]\n",
    "\n",
    "    wave_r = np.fft.ifft(trans)\n",
    "    mag = np.sqrt(wave_r.real ** 2 + wave_r.imag ** 2) #S(x)\n",
    "\n",
    "    return mag, maglog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oM7NiwJooILe"
   },
   "outputs": [],
   "source": [
    "class gen_set():\n",
    "    def __init__(self, width, train_data):\n",
    "\n",
    "        self.len = 0\n",
    "        self.width = width\n",
    "        self.train_data = train_data\n",
    "        self.negrawlen = len(self.train_data)\n",
    "        print('length :', len(self.train_data))\n",
    "        \n",
    "        self.len += self.negrawlen\n",
    "        self.kpineglen = 0\n",
    "        self.control = 0.\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        idx = index % self.negrawlen\n",
    "        datas = np.array(self.train_data[idx])  # (2,128)\n",
    "        data = datas[0, :].astype(np.float32)\n",
    "        lbs = datas[1, :].astype(np.float32)\n",
    "        \n",
    "        wave, maglog = spectral_residual(data)\n",
    "        waveavg = average_filter(wave)\n",
    "        \n",
    "        for i in range(self.width):   # 調整 Label的設置 #\n",
    "            if wave[i] < 0.001 and waveavg[i] < 0.001:\n",
    "                lbs[i] = 0\n",
    "                continue\n",
    "            ratio = wave[i] / waveavg[i]\n",
    "            if ratio < 1.0 and lbs[i] == 1:\n",
    "                lbs[i] = 0\n",
    "            if ratio > 5.0:\n",
    "                lbs[i] = 1\n",
    "                \n",
    "        srscore = abs(wave - waveavg) / (waveavg + 0.01)\n",
    "        sortid = np.argsort(srscore)\n",
    "        for idx in sortid[-2:]:\n",
    "            if srscore[idx] > 5:\n",
    "                lbs[idx] = 1\n",
    "                \n",
    "        resdata = 100 * np.array(wave)\n",
    "        reslb = lbs\n",
    "        \n",
    "        return resdata, reslb, maglog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5559,
     "status": "ok",
     "timestamp": 1591589181184,
     "user": {
      "displayName": "郭又嘉",
      "photoUrl": "",
      "userId": "15699708202644108089"
     },
     "user_tz": -480
    },
    "id": "w3TtaXxuoILi",
    "outputId": "6da778e0-1263-4c9e-b839-c46dd5aff9d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 8951\n",
      "train_x shape (7160, 64)\n",
      "train_y.shape (7160, 64)\n",
      "vali_x shape (1791, 64)\n",
      "vali_y.shape (1791, 64)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "gen_data = gen_set(window, X_train)\n",
    "data_list = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    data_list.append(gen_data.__getitem__(i))\n",
    "    \n",
    "X, Y = np.array(data_list)[:,0], np.array(data_list)[:,1]\n",
    "'''train_x = X[:int(X.shape[0]*0.8)].astype(np.float32)\n",
    "train_y = Y[:int(Y.shape[0]*0.8)].astype(np.float32)\n",
    "vali_x = X[int(X.shape[0]*0.8):].astype(np.float32)\n",
    "vali_y = Y[int(Y.shape[0]*0.8):].astype(np.float32)'''\n",
    "\n",
    "train_x, vali_x, train_y, vali_y = train_test_split(X.astype(np.float32), Y.astype(np.float32), test_size=0.2, random_state=42)\n",
    "\n",
    "print('train_x shape', train_x.shape)\n",
    "print('train_y.shape', train_y.shape)\n",
    "print('vali_x shape', vali_x.shape)\n",
    "print('vali_y.shape', vali_y.shape)\n",
    "\n",
    "train_buf = len(train_x)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=train_buf)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "vali_buf = len(vali_x)\n",
    "vali_dataset = tf.data.Dataset.from_tensor_slices((vali_x, vali_y))\n",
    "vali_dataset = vali_dataset.shuffle(buffer_size=vali_buf)\n",
    "vali_dataset = vali_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Heyg52Zx4mFd"
   },
   "source": [
    "## SR Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4677,
     "status": "ok",
     "timestamp": 1591589181185,
     "user": {
      "displayName": "郭又嘉",
      "photoUrl": "",
      "userId": "15699708202644108089"
     },
     "user_tz": -480
    },
    "id": "1BEg40kb4mFe",
    "outputId": "f3d8ec60-1c5d-448d-a981-8eb6767f6ced"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"threshold = 3\\naa = np.reshape(train_x, [1, -1])\\nres = np.where(aa > threshold, 1, 0)[0]\\nbb = np.reshape(train_y, [1, -1])[0]\\n\\nf1 = f1_score(bb, res)\\nprint('F1', f1)\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''threshold = 3\n",
    "aa = np.reshape(train_x, [1, -1])\n",
    "res = np.where(aa > threshold, 1, 0)[0]\n",
    "bb = np.reshape(train_y, [1, -1])[0]\n",
    "\n",
    "f1 = f1_score(bb, res)\n",
    "print('F1', f1)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZY6KXPFqXRFv"
   },
   "source": [
    "## log(A(f)) -- 前100筆window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3623,
     "status": "ok",
     "timestamp": 1591589181186,
     "user": {
      "displayName": "郭又嘉",
      "photoUrl": "",
      "userId": "15699708202644108089"
     },
     "user_tz": -480
    },
    "id": "bDf143GeXRFw",
    "outputId": "2ff01df8-f5a3-47f9-f161-b3eebaafb04d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in range(100):\\n    print(\\'picture  \\', i)\\n    plt.plot(np.array(data_list)[:,2][i])\\n    index_changes = np.where(train_y[i] == 1)\\n    plt.scatter(index_changes, np.array(data_list)[:,2][i][index_changes], c=\\'red\\', label=\"change point\")\\n    plt.legend()\\n    plt.show()'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in range(100):\n",
    "    print('picture  ', i)\n",
    "    plt.plot(np.array(data_list)[:,2][i])\n",
    "    index_changes = np.where(train_y[i] == 1)\n",
    "    plt.scatter(index_changes, np.array(data_list)[:,2][i][index_changes], c='red', label=\"change point\")\n",
    "    plt.legend()\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vPcysANmXRFy"
   },
   "source": [
    "## 轉SR的Time Series與Label標記情況(前100筆window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2562,
     "status": "ok",
     "timestamp": 1591589181187,
     "user": {
      "displayName": "郭又嘉",
      "photoUrl": "",
      "userId": "15699708202644108089"
     },
     "user_tz": -480
    },
    "id": "WLoZ1W1kXRFy",
    "outputId": "bba0a968-1a5c-47aa-bf63-c49bf84e0c8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in range(100):\\n    print(\\'picture  \\', i)\\n    plt.plot(train_x[i])\\n    index_changes = np.where(train_y[i] == 1)\\n    plt.scatter(index_changes, train_x[i][index_changes], c=\\'red\\', label=\"change point\")\\n    plt.legend()\\n    plt.show()'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in range(100):\n",
    "    print('picture  ', i)\n",
    "    plt.plot(train_x[i])\n",
    "    index_changes = np.where(train_y[i] == 1)\n",
    "    plt.scatter(index_changes, train_x[i][index_changes], c='red', label=\"change point\")\n",
    "    plt.legend()\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aQq7ZHaHjoMU"
   },
   "source": [
    "## 加入CNN做訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1499,
     "status": "ok",
     "timestamp": 1591589181189,
     "user": {
      "displayName": "郭又嘉",
      "photoUrl": "",
      "userId": "15699708202644108089"
     },
     "user_tz": -480
    },
    "id": "vkutwVgMoILm",
    "outputId": "f17db0ad-2ff6-406d-bf14-009bf775e630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 64, 64)            128       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 64, 128)           8320      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "=================================================================\n",
      "Total params: 2,122,304\n",
      "Trainable params: 2,122,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_anomaly_model():\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(window, 1))  \n",
    "\n",
    "    x = layers.Conv1D(window, kernel_size=1, padding='valid', strides=1, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-4, l2=1e-4))(inputs)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv1D(2 * window, kernel_size=1, padding='valid', strides=1, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-4, l2=1e-4))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(4 * window, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-4, l2=1e-4))(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(window, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-4, l2=1e-4))(x)  # sigmoid 在 loss 加上 \n",
    "    model = tf.keras.Model(inputs = inputs, outputs=x)\n",
    "    \n",
    "    return model\n",
    "anomaly_model = make_anomaly_model()\n",
    "anomaly_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nRXOqzqLoILq"
   },
   "outputs": [],
   "source": [
    "def adjust_lr(epoch, lr):\n",
    "    cur_lr = lr * (0.5 ** ((epoch + 10) // 10))\n",
    "    return cur_lr\n",
    "\n",
    "def calc(pred, true):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    for pre, gt in zip(pred, true):\n",
    "        if gt == 1:\n",
    "            if pre == 1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        if gt == 0:\n",
    "            if pre == 1:\n",
    "                FP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "    return TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48cz4Nh0oILx"
   },
   "outputs": [],
   "source": [
    "class SRCNN():\n",
    "    \n",
    "    def __init__(self, anomaly_model, weight, lr):\n",
    "        self.anomaly_model = anomaly_model\n",
    "        self.weight = weight\n",
    "        self.clr = lr\n",
    "        self.optimizer = tf.keras.optimizers.Adam(lr = self.clr)   #############\n",
    " \n",
    "    def weight_binary_crossentropy(self, y_true, y_pred):\n",
    "        #weight = 1\n",
    "        loss = tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, pos_weight = self.weight)\n",
    "        #loss = tf.nn.sigmoid_cross_entropy_with_logits(tf.reshape(y_true, [-1,1]), y_pred) \n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_model(self, batch_x, batch_y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predict = self.anomaly_model(batch_x, training=True)\n",
    "            output_loss = self.weight_binary_crossentropy(batch_y, predict)\n",
    "\n",
    "        grads = tape.gradient(output_loss, anomaly_model.trainable_variables)\n",
    "        grads, _ = tf.clip_by_global_norm(grads, 5.0)\n",
    "        self.optimizer.apply_gradients(zip(grads, anomaly_model.trainable_variables))\n",
    "\n",
    "        return output_loss, predict\n",
    "    \n",
    "    def SRCNN_train(self, dataset, show_loss):\n",
    "\n",
    "        n_epochs = 10000\n",
    "        start = 0\n",
    "        pre_loss = 0\n",
    "\n",
    "        loss_list = []\n",
    "        now_clr = self.clr\n",
    "        for epoch in range(n_epochs):\n",
    "            start = time.time()\n",
    "\n",
    "            epoch_loss_avg = tf.metrics.Mean()\n",
    "\n",
    "            for batch_id, (batch) in enumerate(dataset):\n",
    "                batch_x, batch_y = batch[0], batch[1]\n",
    "\n",
    "                self.optimizer.lr = self.clr\n",
    "                loss_, output = self.train_model(tf.expand_dims(batch_x, axis=2), batch_y)\n",
    "                epoch_loss_avg(loss_)\n",
    "\n",
    "            loss_list.append(epoch_loss_avg.result())\n",
    "\n",
    "            if abs(pre_loss - epoch_loss_avg.result()) < 1e-8:\n",
    "                break\n",
    "            pre_loss = epoch_loss_avg.result()\n",
    "\n",
    "            if show_loss:\n",
    "                epoch_time = time.time() - start\n",
    "                if epoch % 100 == 0:\n",
    "                    epoch_time = time.time() - start\n",
    "                    print('{:4d}: TIME: {:.2f} LOSS: {:.6f} '.format(epoch, epoch_time, epoch_loss_avg.result()))\n",
    "\n",
    "        final_loss = epoch_loss_avg.result()\n",
    "        return final_loss, loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c3oyIBK_E9v2"
   },
   "source": [
    "## 貝氏最佳化找超參數weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMgjlSY7VSTv"
   },
   "outputs": [],
   "source": [
    "space  = [Real(10**-3, 10**3, 'uniform', name='weight')]\n",
    "          #Real(0, 1, 'uniform', name='threshold')]\n",
    "@use_named_args(space)\n",
    "def ValidateModel(weight):\n",
    "    global X,Y\n",
    "    train_x, vali_x, train_y, vali_y = train_test_split(X.astype(np.float32), Y.astype(np.float32), test_size=0.2, random_state=42)\n",
    "   \n",
    "    anomaly_model.load_weights('anomaly_model_weight')\n",
    "    srcnn = SRCNN(anomaly_model, weight, 1e-6)\n",
    "    loss, _ = srcnn.SRCNN_train(train_dataset, False)\n",
    "    \n",
    "    predicts = tf.reshape(anomaly_model(tf.expand_dims(vali_x, axis=2), training=False), [-1,1])\n",
    "    vali_y = tf.reshape(vali_y, [-1,1])\n",
    "\n",
    "    threshold = np.quantile(predicts[vali_y==1], 0.1)  # 0.1的異常被判斷錯誤 的閥值\n",
    "    pre = [1 if item > threshold else 0 for item in predicts]\n",
    "    \n",
    "    '''best_valipre = 0\n",
    "    for i in range(0, 99, 10):\n",
    "        threshold = 0.01 + i * 0.01\n",
    "        pre = [1 if item > threshold else 0 for item in predicts]\n",
    "        vali_pre = precision_score(vali_y, pre)\n",
    "        \n",
    "        if vali_pre > best_valipre:\n",
    "            best_valipre = vali_pre\n",
    "            bestthre = threshold'''\n",
    "        \n",
    "    #vali_f1 = f1_score(vali_y, pre)\n",
    "    vali_rec = recall_score(vali_y, pre)\n",
    "\n",
    "    print('weight :', weight, 'loss :', loss.numpy(), 'threshold', threshold, 'recall score', vali_rec)\n",
    "    \n",
    "    return -vali_rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 138216,
     "status": "error",
     "timestamp": 1591589353959,
     "user": {
      "displayName": "郭又嘉",
      "photoUrl": "",
      "userId": "15699708202644108089"
     },
     "user_tz": -480
    },
    "id": "ONVl3uqKVSTx",
    "outputId": "a5a4da79-d050-4113-a478-e14d6d86d52a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : 851.6617384285387 loss : 0.14750533 precision score 0.458041958041958\n",
      "weight : 22.073787135988415 loss : 0.14303635 precision score 0.5101270168211466\n",
      "weight : 810.5761634155285 loss : 0.3267061 precision score 0.338213293438769\n",
      "weight : 237.58022798904102 loss : 0.11297866 precision score 0.4818582570362835\n"
     ]
    }
   ],
   "source": [
    "search_result = gp_minimize(ValidateModel, space, n_calls = 15)   # n_calls default=100\n",
    "print(\"best F1:\", -search_result.fun)   # 找出最小的 function value at the minimum.\n",
    "print(search_result.x)                  # location of the minimum.\n",
    "weight_opt = search_result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二次選"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : 1.6481561077844222 loss : 0.060743585 F1 score 0.7013168954889326\n",
      "weight : 2.597509736638074 loss : 0.052348055 F1 score 0.6660638160444388\n",
      "weight : 3.1112505912903456 loss : 0.0799901 F1 score 0.696526508226691\n",
      "weight : 1.6911170793937884 loss : 0.056627713 F1 score 0.6995403259506896\n",
      "weight : 0.574356291162582 loss : 0.025517024 F1 score 0.6776345042240995\n",
      "weight : 0.3932635795956472 loss : 0.0237995 F1 score 0.6584004959702418\n",
      "weight : 3.0782801056852898 loss : 0.07675394 F1 score 0.6971518160438985\n",
      "weight : 1.8000162301595135 loss : 0.060218327 F1 score 0.7026877251316154\n",
      "weight : 0.48378331642034855 loss : 0.026766092 F1 score 0.6672774469384639\n",
      "weight : 0.042881798116385 loss : 0.0044340664 F1 score 0.5669559298962056\n",
      "best F1: 0.7026877251316154\n",
      "[1.8000162301595135]\n"
     ]
    }
   ],
   "source": [
    "w_2 = weight_opt[0]\n",
    "space  = [Real(0, w_2 * (1.5), 'uniform', name='weight')]\n",
    "          #Real(0, 1, 'uniform', name='threshold')]\n",
    "\n",
    "search_result = gp_minimize(ValidateModel, space, n_calls = 10)   # n_calls default=100\n",
    "print(\"best F1:\", -search_result.fun)   # 找出最小的 function value at the minimum.\n",
    "print(search_result.x)                  # location of the minimum.\n",
    "weight_opt = search_result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3rD9mQRS4mFv"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19576,
     "status": "ok",
     "timestamp": 1591588983881,
     "user": {
      "displayName": "郭又嘉",
      "photoUrl": "",
      "userId": "15699708202644108089"
     },
     "user_tz": -480
    },
    "id": "MUB87q0K4mFv",
    "outputId": "f2457e14-d270-42fd-e2fb-63c248aa6ea2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"choice_weight = weight_opt[0]\\nanomaly_model.load_weights('anomaly_model_weight')\\nsrcnn = SRCNN(anomaly_model, choice_weight, 1e-6)\\n_, loss_list = srcnn.SRCNN_train(train_dataset, True)\\n\\nplt.plot(loss_list)\\nplt.show()\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''choice_weight = weight_opt[0]\n",
    "anomaly_model.load_weights('anomaly_model_weight')\n",
    "srcnn = SRCNN(anomaly_model, choice_weight, 1e-6)\n",
    "_, loss_list = srcnn.SRCNN_train(train_dataset, True)\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eR89jBAToIL1"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "siweUrlFoIL2"
   },
   "outputs": [],
   "source": [
    "def predict_next(values):\n",
    "    \"\"\"\n",
    "    Predicts the next value by sum up the slope of the last value with previous values.\n",
    "    Mathematically, g = 1/m * sum_{i=1}^{m} g(x_n, x_{n-i}), x_{n+1} = x_{n-m+1} + g * m,\n",
    "    where g(x_i,x_j) = (x_i - x_j) / (i - j)\n",
    "    :param values: list.\n",
    "        a list of float numbers.\n",
    "    :return : float.\n",
    "        the predicted next value.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(values) <= 1:\n",
    "        raise ValueError(f'data should contain at least 2 numbers')\n",
    "    \n",
    "    v_last = values[-1]\n",
    "    n = len(values)\n",
    "\n",
    "    slopes = [(v_last - v) / (n - 1 - i) for i, v in enumerate(values[:-1])]\n",
    "\n",
    "    return values[1] + sum(slopes)\n",
    "\n",
    "def extend_series(values, extend_num=5, look_ahead=5):\n",
    "    \"\"\"\n",
    "    extend the array data by the predicted next value\n",
    "    :param values: list.\n",
    "        a list of float numbers.\n",
    "    :param extend_num: int, default 5.\n",
    "        number of values added to the back of data.\n",
    "    :param look_ahead: int, default 5.\n",
    "        number of previous values used in prediction.\n",
    "    :return: list.\n",
    "        The result array.\n",
    "    \"\"\"\n",
    "\n",
    "    if look_ahead < 1:\n",
    "        raise ValueError('look_ahead must be at least 1')\n",
    "    values = list(values)\n",
    "    extension = [predict_next(values[-look_ahead - 2:-1])] * extend_num\n",
    "    return values + extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bGHH6tpLoIL5"
   },
   "outputs": [],
   "source": [
    "def get_range_proba(predict, label, delay=7):\n",
    "    predict = np.array(predict)\n",
    "    label = np.array(label)\n",
    "\n",
    "    splits = np.where(label[1:] != label[:-1])[0] + 1\n",
    "    is_anomaly = label[0] == 1\n",
    "    new_predict = np.array(predict)\n",
    "    pos = 0\n",
    "\n",
    "    for sp in splits:\n",
    "        if is_anomaly:\n",
    "            if 1 in predict[pos:min(pos + delay + 1, sp)]:\n",
    "                new_predict[pos: sp] = 1\n",
    "            else:\n",
    "                new_predict[pos: sp] = 0\n",
    "        is_anomaly = not is_anomaly\n",
    "        pos = sp\n",
    "    sp = len(label)\n",
    "\n",
    "    if is_anomaly:\n",
    "        if 1 in predict[pos: min(pos + delay + 1, sp)]:\n",
    "            new_predict[pos: sp] = 1\n",
    "        else:\n",
    "            new_predict[pos: sp] = 0\n",
    "\n",
    "    return new_predict\n",
    "\n",
    "\n",
    "def reconstruct_label(timestamp, label):\n",
    "    \n",
    "    timestamp = np.asarray(timestamp)\n",
    "    index = np.argsort(timestamp)\n",
    "\n",
    "    timestamp_sorted = np.asarray(timestamp[index])\n",
    "    interval = np.min(np.diff(timestamp_sorted))\n",
    "\n",
    "    label = np.asarray(label, np.int64)\n",
    "    label = np.asarray(label[index])\n",
    "\n",
    "    idx = (timestamp_sorted - timestamp_sorted[0]) // interval\n",
    "\n",
    "    new_label = np.zeros(shape=((timestamp_sorted[-1] - timestamp_sorted[0]) // interval + 1,), dtype=np.int)\n",
    "    new_label[idx] = label\n",
    "\n",
    "    return new_label\n",
    "\n",
    "\n",
    "def reconstruct_series(timestamp, label, predict, delay=7):\n",
    "    \n",
    "    label = reconstruct_label(timestamp, label)\n",
    "    predict = reconstruct_label(timestamp, predict)\n",
    "    predict = get_range_proba(predict, label, delay)  # 考慮延遲異常點\n",
    "    return list(label), list(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKVG2FwOoIL7"
   },
   "outputs": [],
   "source": [
    "def evaluate_for_all_series(lst_timestamp_label_predict, delay=7, prt=True):\n",
    "    labels, predicts = [], []\n",
    "    for timestamp, label, predict in lst_timestamp_label_predict:\n",
    "        if timestamp == []:\n",
    "            continue\n",
    "        lbl, pdt = reconstruct_series(timestamp, label, predict, delay)\n",
    "        labels += lbl\n",
    "        predicts += pdt\n",
    "\n",
    "    f1 = f1_score(labels, predicts)\n",
    "    pre = precision_score(labels, predicts)\n",
    "    rec = recall_score(labels, predicts)\n",
    "    TP, FP, TN, FN = calc(predicts, labels)\n",
    "    auc = roc_auc_score(labels, predicts)\n",
    "    if prt:\n",
    "        print('precision', pre)\n",
    "        print('recall', rec)\n",
    "        print('f1', f1)\n",
    "        print('TP: {:} FP: {:} TN: {:} FN: {:}'.format(TP, FP, TN, FN))\n",
    "        print('AUC', auc)\n",
    "        print('-------------------------------')\n",
    "    return f1, pre, rec, TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAZFviFSXRGQ"
   },
   "outputs": [],
   "source": [
    "def window_test(timestamp, value, back_k=0, backaddnum=5, step=32):\n",
    "\n",
    "    win_size = window\n",
    "    length = len(timestamp)\n",
    "    if back_k <= 5:\n",
    "        back = back_k\n",
    "    else:\n",
    "        back = 5\n",
    "        \n",
    "    mag_list = []\n",
    "    for pt in range(int(win_size - backaddnum + back + step), int(length - back), step):\n",
    "        head = max(0, pt - (win_size - backaddnum))\n",
    "        tail = min(length, pt)\n",
    "        wave = np.array(extend_series(value[head:tail + back])) # backaddnum = 增加K個估計點 K=5\n",
    "        mag, _ = spectral_residual(wave)\n",
    "        mag_list.append(mag)\n",
    "    \n",
    "    return mag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHmc34VfoIL-"
   },
   "outputs": [],
   "source": [
    "def sr_cnn_eval(SR_output, timestamp, value, label, ms_optioin, threshold=0.95, back_k=0, backaddnum=5, step=32):\n",
    "\n",
    "    def modelwork(x):\n",
    "        x = 100 * np.array(x)\n",
    "        x = np.expand_dims(x, axis=2)\n",
    "        \n",
    "        #anomaly_model = tf.keras.models.load_model('anomaly_model_yahoo_test3_n.h5', compile=False)\n",
    "        output = tf.math.sigmoid(anomaly_model(x, training=False))\n",
    "        aa = np.reshape(output, [1, -1])\n",
    "        res = np.where(aa > threshold, 1, 0)\n",
    "        aa = np.reshape(aa, [-1, win_size])\n",
    "        res = np.reshape(res, [-1, win_size])\n",
    "        \n",
    "        return res, aa\n",
    "\n",
    "    win_size = window\n",
    "    length = len(timestamp)\n",
    "    if back_k <= 5:\n",
    "        back = back_k\n",
    "    else:\n",
    "        back = 5\n",
    "    detres = np.zeros((win_size - backaddnum,))\n",
    "    scores = np.zeros((win_size - backaddnum,))\n",
    "\n",
    "    modeloutput, rawout = modelwork(SR_output)\n",
    "    num = 0\n",
    "    for pt in range(int(win_size - backaddnum + back + step), int(length - back), step):\n",
    "        head = max(0, pt - (win_size - backaddnum))\n",
    "        tail = min(length, pt)\n",
    "        modeloutput_ = modeloutput[num,:]\n",
    "        rawout_ = rawout[num,:]\n",
    "        num += 1\n",
    "        \n",
    "        for ipt in range(pt - step - back, pt - back):\n",
    "            detres = np.append(detres, modeloutput_[ipt - head])\n",
    "            scores = np.append(scores, rawout_[ipt - head].item())\n",
    "    \n",
    "    detres = np.append(detres, np.zeros((length - len(detres),)))   # detres : predict結果 [0,1]顯示\n",
    "    scores = np.append(scores, np.zeros((length - len(scores),)))   # scores : predict結果 未切割[0,1]顯示\n",
    "    \n",
    "    if ms_optioin == 'anomaly':\n",
    "        last = -1\n",
    "        \n",
    "        interval = min([timestamp[i] - timestamp[i - 1] for i in range(1, len(timestamp))]) # 計算兩兩間隔時間 取min\n",
    "        for i in range(1, len(timestamp)):\n",
    "            if timestamp[i] - timestamp[i - 1] > interval:\n",
    "                if last >= 0 and i - last < 1000:\n",
    "                    detres[i] = 1\n",
    "                    scores[i] = 1\n",
    "            if detres[i] == 1:\n",
    "                last = i\n",
    "    \n",
    "    return list(timestamp), label[:], detres[:], scores[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZ6TA1r9oIMC"
   },
   "outputs": [],
   "source": [
    "def get_score(thres, option):\n",
    "    total_time = 0\n",
    "    results = []\n",
    "    savedscore = []\n",
    "    \n",
    "    df_test = pd.read_csv('yahoo_total_data.csv')\n",
    "    half_len = int(df_test.shape[0]/2)\n",
    "    in_timestamp, in_value, in_label = df_test['timestamp'][half_len:], df_test['value'][half_len:], df_test['is_anomaly'][half_len:]\n",
    "    \n",
    "    \n",
    "    length = len(in_timestamp)\n",
    "    \n",
    "    time_start = time.time()\n",
    "    SR_output = window_test(np.array(in_timestamp), in_value)\n",
    "    #print(np.array(SR_output).shape)\n",
    "    timestamp, label, pre, scores = sr_cnn_eval(SR_output, np.array(in_timestamp), in_value, in_label, option, thres)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    total_time = time_end - time_start\n",
    "    results.append([timestamp, label, pre])\n",
    "    savedscore.append([label, scores, timestamp])\n",
    "    \n",
    "    return total_time, results, savedscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 102341,
     "status": "ok",
     "timestamp": 1591589092336,
     "user": {
      "displayName": "郭又嘉",
      "photoUrl": "",
      "userId": "15699708202644108089"
     },
     "user_tz": -480
    },
    "id": "T4dZ01spoIMF",
    "outputId": "5d7190c6-d612-4566-ff82-115f9b1221ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer conv1d is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "precision 0.2445902802412203\n",
      "recall 0.9323867478025692\n",
      "f1 0.3875228326542082\n",
      "TP: 1379 FP: 4259 TN: 280745 FN: 100\n",
      "AUC 0.958721548944442\n",
      "-------------------------------\n",
      "time used for making predictions: 206.60539841651917 seconds\n",
      "AUC 0.9856244559404023\n"
     ]
    }
   ],
   "source": [
    "thres = 0.5\n",
    "missing_option = 'anomaly'\n",
    "delay = 3\n",
    "window = 64\n",
    "\n",
    "total_time, results, savedscore = get_score(thres, missing_option)\n",
    "total_fscore, pre, rec, TP, FP, TN, FN = evaluate_for_all_series(results, delay) # 只拿[0,1]結果\n",
    "print('time used for making predictions:', total_time, 'seconds')\n",
    "print('AUC', roc_auc_score(np.array(savedscore)[0][0], np.array(savedscore)[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 160780,
     "status": "error",
     "timestamp": 1591589152433,
     "user": {
      "displayName": "郭又嘉",
      "photoUrl": "",
      "userId": "15699708202644108089"
     },
     "user_tz": -480
    },
    "id": "HvC7Mx83joM0",
    "outputId": "00423ffe-c7d4-4bae-f7d2-a15a37c253cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delay : 3\n",
      "threshold 0.01\n",
      "F1 best 0.03756498406842194\n",
      "TP: 1456 FP: 74584 TN: 210420 FN: 23\n",
      "\n",
      "threshold 0.03\n",
      "F1 best 0.06603212373587151\n",
      "TP: 1443 FP: 40784 TN: 244220 FN: 36\n",
      "\n",
      "threshold 0.05\n",
      "F1 best 0.08793024323083984\n",
      "TP: 1437 FP: 29769 TN: 255235 FN: 42\n",
      "\n",
      "threshold 0.06999999999999999\n",
      "F1 best 0.10734886508352687\n",
      "TP: 1433 FP: 23786 TN: 261218 FN: 46\n",
      "\n",
      "threshold 0.09\n",
      "F1 best 0.125492600052544\n",
      "TP: 1433 FP: 19926 TN: 265078 FN: 46\n",
      "\n",
      "threshold 0.11\n",
      "F1 best 0.14113461158331686\n",
      "TP: 1428 FP: 17329 TN: 267675 FN: 51\n",
      "\n",
      "threshold 0.13\n",
      "F1 best 0.15585980284775464\n",
      "TP: 1423 FP: 15358 TN: 269646 FN: 56\n",
      "\n",
      "threshold 0.15000000000000002\n",
      "F1 best 0.17022809123649457\n",
      "TP: 1418 FP: 13763 TN: 271241 FN: 61\n",
      "\n",
      "threshold 0.17\n",
      "F1 best 0.18485857992030832\n",
      "TP: 1415 FP: 12415 TN: 272589 FN: 64\n",
      "\n",
      "threshold 0.19\n",
      "F1 best 0.19885843140018322\n",
      "TP: 1411 FP: 11301 TN: 273703 FN: 68\n",
      "\n",
      "threshold 0.21000000000000002\n",
      "F1 best 0.2126984126984127\n",
      "TP: 1407 FP: 10344 TN: 274660 FN: 72\n",
      "\n",
      "threshold 0.23\n",
      "F1 best 0.22519634556820003\n",
      "TP: 1405 FP: 9594 TN: 275410 FN: 74\n",
      "\n",
      "threshold 0.25\n",
      "F1 best 0.23876021798365124\n",
      "TP: 1402 FP: 8863 TN: 276141 FN: 77\n",
      "\n",
      "threshold 0.27\n",
      "F1 best 0.25008938148015736\n",
      "TP: 1399 FP: 8310 TN: 276694 FN: 80\n",
      "\n",
      "threshold 0.29000000000000004\n",
      "F1 best 0.26232278659280817\n",
      "TP: 1397 FP: 7775 TN: 277229 FN: 82\n",
      "\n",
      "threshold 0.31\n",
      "F1 best 0.27390536029844886\n",
      "TP: 1395 FP: 7312 TN: 277692 FN: 84\n",
      "\n",
      "threshold 0.33\n",
      "F1 best 0.2850706532869138\n",
      "TP: 1392 FP: 6895 TN: 278109 FN: 87\n",
      "\n",
      "threshold 0.35000000000000003\n",
      "F1 best 0.2965495139408183\n",
      "TP: 1388 FP: 6494 TN: 278510 FN: 91\n",
      "\n",
      "threshold 0.37\n",
      "F1 best 0.3081879791134318\n",
      "TP: 1387 FP: 6135 TN: 278869 FN: 92\n",
      "\n",
      "threshold 0.39\n",
      "F1 best 0.31940918532194784\n",
      "TP: 1384 FP: 5803 TN: 279201 FN: 95\n",
      "\n",
      "threshold 0.41000000000000003\n",
      "F1 best 0.3326123527998078\n",
      "TP: 1384 FP: 5459 TN: 279545 FN: 95\n",
      "\n",
      "threshold 0.43\n",
      "F1 best 0.34568210262828536\n",
      "TP: 1381 FP: 5130 TN: 279874 FN: 98\n",
      "\n",
      "threshold 0.45\n",
      "F1 best 0.3580967198236743\n",
      "TP: 1381 FP: 4853 TN: 280151 FN: 98\n",
      "\n",
      "threshold 0.47000000000000003\n",
      "F1 best 0.3702213279678068\n",
      "TP: 1380 FP: 4596 TN: 280408 FN: 99\n",
      "\n",
      "threshold 0.49\n",
      "F1 best 0.38151888227970676\n",
      "TP: 1379 FP: 4371 TN: 280633 FN: 100\n",
      "\n",
      "threshold 0.51\n",
      "F1 best 0.3932135728542914\n",
      "TP: 1379 FP: 4156 TN: 280848 FN: 100\n",
      "\n",
      "threshold 0.53\n",
      "F1 best 0.40602836879432624\n",
      "TP: 1374 FP: 3915 TN: 281089 FN: 105\n",
      "\n",
      "threshold 0.55\n",
      "F1 best 0.4185904295979208\n",
      "TP: 1369 FP: 3693 TN: 281311 FN: 110\n",
      "\n",
      "threshold 0.5700000000000001\n",
      "F1 best 0.43154574132492113\n",
      "TP: 1368 FP: 3493 TN: 281511 FN: 111\n",
      "\n",
      "threshold 0.59\n",
      "F1 best 0.4439389015274618\n",
      "TP: 1366 FP: 3309 TN: 281695 FN: 113\n",
      "\n",
      "threshold 0.61\n",
      "F1 best 0.45656903765690376\n",
      "TP: 1364 FP: 3132 TN: 281872 FN: 115\n",
      "\n",
      "threshold 0.63\n",
      "F1 best 0.4695742113428719\n",
      "TP: 1362 FP: 2960 TN: 282044 FN: 117\n",
      "\n",
      "threshold 0.65\n",
      "F1 best 0.48439450686641694\n",
      "TP: 1358 FP: 2770 TN: 282234 FN: 121\n",
      "\n",
      "threshold 0.67\n",
      "F1 best 0.49816446402349485\n",
      "TP: 1357 FP: 2612 TN: 282392 FN: 122\n",
      "\n",
      "threshold 0.6900000000000001\n",
      "F1 best 0.5096262740656851\n",
      "TP: 1350 FP: 2469 TN: 282535 FN: 129\n",
      "\n",
      "threshold 0.7100000000000001\n",
      "F1 best 0.5229037267080745\n",
      "TP: 1347 FP: 2326 TN: 282678 FN: 132\n",
      "\n",
      "threshold 0.73\n",
      "F1 best 0.5351157222665603\n",
      "TP: 1341 FP: 2192 TN: 282812 FN: 138\n",
      "\n",
      "threshold 0.75\n",
      "F1 best 0.5494957810249023\n",
      "TP: 1335 FP: 2045 TN: 282959 FN: 144\n",
      "\n",
      "threshold 0.77\n",
      "F1 best 0.5634280865507001\n",
      "TP: 1328 FP: 1907 TN: 283097 FN: 151\n",
      "\n",
      "threshold 0.79\n",
      "F1 best 0.5783027121609798\n",
      "TP: 1322 FP: 1771 TN: 283233 FN: 157\n",
      "\n",
      "threshold 0.81\n",
      "F1 best 0.5954370905805286\n",
      "TP: 1318 FP: 1630 TN: 283374 FN: 161\n",
      "\n",
      "threshold 0.8300000000000001\n",
      "F1 best 0.6113049546406141\n",
      "TP: 1314 FP: 1506 TN: 283498 FN: 165\n",
      "\n",
      "threshold 0.85\n",
      "F1 best 0.6275264677574591\n",
      "TP: 1304 FP: 1373 TN: 283631 FN: 175\n",
      "\n",
      "threshold 0.87\n",
      "F1 best 0.6516290726817042\n",
      "TP: 1300 FP: 1211 TN: 283793 FN: 179\n",
      "\n",
      "threshold 0.89\n",
      "F1 best 0.6755208333333332\n",
      "TP: 1297 FP: 1064 TN: 283940 FN: 182\n",
      "\n",
      "threshold 0.91\n",
      "F1 best 0.6991825613079019\n",
      "TP: 1283 FP: 908 TN: 284096 FN: 196\n",
      "\n",
      "threshold 0.93\n",
      "F1 best 0.7238805970149255\n",
      "TP: 1261 FP: 744 TN: 284260 FN: 218\n",
      "\n",
      "threshold 0.9500000000000001\n",
      "F1 best 0.7491659084015773\n",
      "TP: 1235 FP: 583 TN: 284421 FN: 244\n",
      "\n",
      "threshold 0.97\n",
      "F1 best 0.772225827384815\n",
      "TP: 1190 FP: 413 TN: 284591 FN: 289\n",
      "\n",
      "threshold 0.99\n",
      "F1 best 0.7749453750910414\n",
      "TP: 1064 FP: 203 TN: 284801 FN: 415\n",
      "\n",
      "best overall threshold : 0.99 best F1 score : 0.7749453750910414\n",
      "best precision 0.8397790055248618\n",
      "best recall 0.7194050033806626\n"
     ]
    }
   ],
   "source": [
    "best = 0.\n",
    "bestthre = 0.\n",
    "print('delay :', delay)\n",
    "\n",
    "for i in range(0, 99, 2):  # 考慮不同的 threshold\n",
    "    newresults = []\n",
    "    threshold = 0.01 + i * 0.01\n",
    "    for (flabel, cnnscores, ftimestamp) in savedscore:\n",
    "        pre = [1 if item > threshold else 0 for item in cnnscores]\n",
    "        newresults.append([ftimestamp, flabel, pre])\n",
    "        \n",
    "    total_fscore, pre, rec, TP, FP, TN, FN = evaluate_for_all_series(newresults, delay, prt=False)\n",
    "    \n",
    "    if total_fscore > best:\n",
    "        best = total_fscore\n",
    "        best_pre = pre\n",
    "        best_rec = rec\n",
    "        bestthre = threshold\n",
    "        print('threshold', threshold)\n",
    "        print('F1 best', best)\n",
    "        print('TP: {:} FP: {:} TN: {:} FN: {:}'.format(TP, FP, TN, FN))\n",
    "        print()\n",
    "        \n",
    "threshold = bestthre\n",
    "print('best overall threshold :', threshold, 'best F1 score :', best)\n",
    "print('best precision', best_pre)\n",
    "print('best recall', best_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RVhRsa4-XRGa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tnv5Rpid4mGE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GFlNyCbU4mGG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q2CwQEuH4mGH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SRCNN_Yahoo_Paper(test3)-select_weight_skopt.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
